import streamlit as st
from streamlit_deepgram_interface import st_deepgram
from streamlit_speech_recognition_interface import st_speech
from audio_conversion import *

st.title("MASP Teste - Transcriﾃｧﾃ｣o de ﾃ「dio")

file_path = ""

# Implementation selection
met = st.sidebar.selectbox(
    'Qual ﾃｩ a implementaﾃｧﾃ｣o?',
    ('Speech Recognition', 'Deepgram'),
    key="implementation"
)

if met == 'Speech Recognition':
    file_load_state = st.text('Procurando ﾃ「dio...\nPor Favor Colocar Link Para ﾃ「dio')

    file_path = ""

    # Method selection
    method = st.sidebar.selectbox(
        'Qual ﾃｩ o mﾃｩtodo?',
        ('Live Capture', 'File Path'),
        key="method"
    )
    
    size = "reg"

    if method == 'File Path':
        file_path = st.sidebar.text_input(
            "Coloque o File Path do ﾃ｡udio aqui! 汨",
            key="file_path"
        )

        if file_path:
            st.write("\n\nYou entered: ", file_path)
        
        file_size = st.sidebar.selectbox(
            'Qual ﾃｩ o tamanho do arquivo?',
            ('Regular', 'Grande'),
            key='speech_recognition_file_size'
        )
        
        if file_size == 'Grande':
            size = 'big'

    # Language selection
    language = st.sidebar.selectbox(
        'Qual ﾃｩ o idioma?',
        ('Portuguﾃｪs', 'English'),
        key='speech_recognition_language'
    )

    if language == 'English':
        language = 'en'
    else:
        language = "pt-BR"

    if st.sidebar.button("Transcrever ﾃ「dio", key="transcribe_speech_recognition"):
        if method == 'Live Capture':
            # Habilita o microfone para ouvir o usuﾃ｡rio
            microfone = sr.Recognizer()
            with sr.Microphone() as source:
                # Chama a funﾃｧﾃ｣o de reduﾃｧﾃ｣o de ruﾃｭdo disponﾃｭvel no speech_recognition
                microfone.adjust_for_ambient_noise(source)
                # Avisa ao usuﾃ｡rio que estﾃ｡ pronto para ouvir
                st.write("Diga alguma coisa: ")
                # Armazena a informaﾃｧﾃ｣o de ﾃ｡udio na variﾃ｡vel
                audio = microfone.listen(source)
                
            try:
                # Passa o ﾃ｡udio para o reconhecedor de padrﾃｵes do speech_recognition
                frase = microfone.recognize_google(audio, language=language)
                # Apﾃｳs alguns segundos, retorna a frase falada
                st.write("Vocﾃｪ disse: " + frase)
            # Caso nﾃ｣o tenha reconhecido o padrﾃ｣o de fala, exibe esta mensagem
            except sr.UnknownValueError:
                st.write("Nﾃ｣o entendi")
            except sr.RequestError:
                st.write("Nﾃ｣o foi possﾃｭvel se conectar ao serviﾃｧo de reconhecimento de fala.")
        else:
            if size == 'reg':
                st.write("O ﾃ｡udio diz: " + transcribe_audio(file_path, language))
            else:
                st.write("O ﾃ｡udio diz: " + get_large_audio_transcription_on_silence(file_path, language))
            
elif met == 'Deepgram':
    file_load_state = st.text('Procurando ﾃ「dio...\nPor Favor Colocar Link Para ﾃ「dio')

    file_path = st.sidebar.text_input(
        "Coloque a URL do ﾃ｡udio aqui! 汨",
        key="deepgram_file_path"
    )

    if file_path:
        st.write("\n\nYou entered: ", file_path)

    # Language selection for Deepgram
    algorithm = st.sidebar.selectbox(
        'Qual ﾃｩ o idioma?',
        ('Portuguﾃｪs', 'English'),
        key="deepgram_language"
    )

    if algorithm == 'English':
        language = 'en'
    else:
        language = "pt-BR"

    if st.sidebar.button("Transcrever ﾃ「dio", key="transcribe_deepgram"):
        try:
            text = convert_deepgram(url=file_path, language=language)
            file_load_state.text(text)
        except Exception as e:
            file_load_state.text(str(e))
